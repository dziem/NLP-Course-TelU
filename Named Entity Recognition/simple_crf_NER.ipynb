{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_crf_NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMf1EyNfPyqo",
        "colab_type": "code",
        "outputId": "04dcbe8a-890c-41d9-d0d8-008e14697430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "!pip install weighted_levenshtein\n",
        "!pip install sklearn-pycrfsuite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: weighted_levenshtein in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Collecting sklearn-pycrfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/17/1c/d80272229ab530d05a157113908c707e642cd1e710e1d7b2bd6fd1e708dc/sklearn-pycrfsuite-0.4.0.tar.gz\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pycrfsuite) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-pycrfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-pycrfsuite) (0.8.6)\n",
            "Collecting python-crfsuite-extension\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/a8/f58b1b803fe9f3a96b501aa5558320fa8c3a3f80b715278bc32a1831ae3a/python-crfsuite-extension-0.9.7.tar.gz (485kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 13.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn-pycrfsuite, python-crfsuite-extension\n",
            "  Building wheel for sklearn-pycrfsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn-pycrfsuite: filename=sklearn_pycrfsuite-0.4.0-py2.py3-none-any.whl size=11002 sha256=9ca1ac42c6126d881b0e548c7348eb0007c11140ff39b8d562a1e6da18630999\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/78/bd/189a8a1d7a6031ce1e1f8e81a5a8bdb0d3fba7e88c53f96107\n",
            "  Building wheel for python-crfsuite-extension (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-crfsuite-extension: filename=python_crfsuite_extension-0.9.7-cp36-cp36m-linux_x86_64.whl size=779517 sha256=406d86a2eb466e34b0c65035bcbe096dc920670112f4add3ab25cb7cf72b6253\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ee/fa/10e4ae5dd9e71190ce1318fa7e2b82314bc880da1ec34ee567\n",
            "Successfully built sklearn-pycrfsuite python-crfsuite-extension\n",
            "Installing collected packages: python-crfsuite-extension, sklearn-pycrfsuite\n",
            "Successfully installed python-crfsuite-extension-0.9.7 sklearn-pycrfsuite-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNubvmBSP838",
        "colab_type": "code",
        "outputId": "d1c65cc5-7284-4595-8d30-9e5e1460886a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder = '/content/drive/My Drive/ner/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqcj6JyqP-yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from weighted_levenshtein import lev, osa, dam_lev\n",
        "from string import ascii_lowercase\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import sklearn\n",
        "import pycrfsuite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95vP8RwKQBDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baca file train dan test\n",
        "train_lines = []\n",
        "test_lines = []\n",
        "with open(folder+'dataTrain.txt', 'r') as f:\n",
        "    train_lines = f.readlines()\n",
        "with open(folder+'kalimat_POSTag.txt', 'r') as f:\n",
        "    test_lines = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgy5uDSdW5Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#baca file list/gazeteer\n",
        "per_list = []\n",
        "flist = open(folder+\"per_list.txt\", \"r\")\n",
        "for p in flist:\n",
        "    per_list.append(p[:-1])\n",
        "\n",
        "loc_list = []\n",
        "llist = open(folder+\"loc_list.txt\", \"r\")\n",
        "for l in llist:\n",
        "    loc_list.append(l[:-1])\n",
        "\n",
        "org_list = []\n",
        "olist = open(folder+\"org_list.txt\", \"r\")\n",
        "for o in olist:\n",
        "    org_list.append(o[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teZBu1wfQqmI",
        "colab_type": "code",
        "outputId": "a7a0e1bf-a9cc-41d1-e40f-49414cd00dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_sents = []\n",
        "test_sents = []\n",
        "sent = []\n",
        "counter = 0\n",
        "for line in train_lines:\n",
        "    line = line.rstrip('\\n')\n",
        "    curr_tuple = ()\n",
        "    if len(line)>1:\n",
        "        line_part = line.split(\" \")\n",
        "        t = (line_part[0], line_part[1], line_part[2])\n",
        "        #print(t)\n",
        "        sent.append(t)\n",
        "    else:\n",
        "        #print(\"train sent = \")\n",
        "        #print(sent)\n",
        "        train_sents.append(sent)\n",
        "        sent = []\n",
        "        counter = counter+1\n",
        "counter = 0\n",
        "sent = []\n",
        "for line in test_lines:\n",
        "    line = line.rstrip('\\n')\n",
        "    curr_tuple = ()\n",
        "    if len(line)>1:\n",
        "        line_part = line.split(\" \")\n",
        "        t = (line_part[0], line_part[1])\n",
        "        #print(t)\n",
        "        sent.append(t)\n",
        "    else:\n",
        "        #print(\"test sent = \")\n",
        "        #print(sent)\n",
        "        test_sents.append(sent)\n",
        "        sent = []\n",
        "        counter = counter+1\n",
        "test_sents.pop()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-FgZlXRWxKW",
        "colab_type": "code",
        "outputId": "b0df6ff7-993a-47b0-d9ea-6bac87e05dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#fungsi list lookup with edit distance\n",
        "alfha = 0.4\n",
        "threshold = 20\n",
        "\n",
        "insert_costs = np.full(128, 100, dtype=np.float64)\n",
        "insert_costs[ord('-')] = 10\n",
        "insert_costs[ord(' ')] = 10\n",
        "\n",
        "delete_costs = np.full(128, 100, dtype=np.float64)\n",
        "delete_costs[ord('-')] = 10\n",
        "delete_costs[ord(' ')] = 10\n",
        "\n",
        "substitute_costs = np.full((128,128), 50, dtype=np.float64)\n",
        "for c in ascii_lowercase:\n",
        "\tsubstitute_costs[ord(c), ord(c.capitalize())] = 10\n",
        "\tsubstitute_costs[ord(c), ord(c)] = 0\n",
        "\tsubstitute_costs[ord(c.capitalize()), ord(c)] = 10\n",
        "\tsubstitute_costs[ord(c.capitalize()), ord(c.capitalize())] = 0\n",
        "substitute_costs[ord('-'), ord(' ')] = 10\n",
        "substitute_costs[ord(' '), ord('-')] = 10\n",
        "for i in range(10):\n",
        "\tfor j in range(10):\n",
        "\t\tif i == j:\n",
        "\t\t\tsubstitute_costs[ord(str(i)), ord(str(j))] = 0\n",
        "\t\t\tsubstitute_costs[ord(str(j)), ord(str(i))] = 0\n",
        "\t\telse:\n",
        "\t\t\tsubstitute_costs[ord(str(i)), ord(str(j))] = 10\n",
        "\t\t\tsubstitute_costs[ord(str(j)), ord(str(i))] = 10\n",
        "\n",
        "def edit_distance_normalized_cost(word, target):\n",
        "\tcost = lev(word, target, insert_costs=insert_costs, delete_costs=delete_costs, substitute_costs=substitute_costs)\n",
        "\treturn (cost + alfha) / len(target)\n",
        "\n",
        "def check_under_threshold(cost):\n",
        "\tif cost <= threshold:\n",
        "\t\treturn True\n",
        "\telse:\n",
        "\t\treturn False\n",
        "\n",
        "def check_list(sentence, pos, list):\n",
        "  words = sentence.split()\n",
        "  candidate = []\n",
        "  candidate.append(words[pos])\n",
        "  if pos >= 0:\n",
        "    if pos < (len(words) - 1):\n",
        "      candidate.append(words[pos] + \" \" + words[pos + 1])\n",
        "    if pos < (len(words) - 2):\n",
        "      candidate.append(words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
        "  if (pos - 1) >= 0:\n",
        "    candidate.append(words[pos - 1] + \" \" + words[pos])\n",
        "    if pos < (len(words) - 1):\n",
        "      candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
        "    if pos < (len(words) - 2):\n",
        "      candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
        "  if (pos - 2) >= 0:\n",
        "    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos])\n",
        "    if pos < (len(words) - 1):\n",
        "      candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
        "    if pos < (len(words) - 2):\n",
        "      candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
        "  exist = 'False'\n",
        "  for l in list:\n",
        "    for c in candidate:\n",
        "      if check_under_threshold(edit_distance_normalized_cost(c,l)) :\n",
        "        exist = 'True'\n",
        "        break\n",
        "  return exist\n",
        "print(check_list('Universitas Gadjah Mada',0,org_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3brA6oWJQ8_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    sentence = ''\n",
        "    for w in sent:\n",
        "      sentence += w[0] + \" \"\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(),\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "        'postag=' + postag,\n",
        "        'postag[:2]=' + postag[:2],\n",
        "        'inPerList=' + check_list(sentence,i,per_list), #check di list person\n",
        "        'inLocList=' + check_list(sentence,i,loc_list), #check di list location\n",
        "        'inOrgList=' + check_list(sentence,i,org_list) #check di list organisation\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "            '-1:postag=' + postag1,\n",
        "            '-1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "            '+1:postag=' + postag1,\n",
        "            '+1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o96uB3knRPX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "#y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1s1tVGzRTtJ",
        "colab_type": "code",
        "outputId": "236209bc-df56-40b9-d13d-6205c19471c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})\n",
        "\n",
        "trainer.train('sample.crfsuite')\n",
        "\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('sample.crfsuite')\n",
        "file = open(folder+'crf_output.txt','w') \n",
        "#example_sent = test_sents[0]\n",
        "#print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
        "for zz in test_sents:\n",
        "  pred = tagger.tag(sent2features(zz))\n",
        "  for ww in range(len(zz)):\n",
        "    #print(zz[ww][0],pred[ww])\n",
        "    file.write(zz[ww][0])\n",
        "    file.write('\\t')\n",
        "    file.write(pred[ww])\n",
        "    file.write('\\n')\n",
        "  #print('\\n')\n",
        "  file.write('\\n')\n",
        "print('finished')\n",
        "file.close()\n",
        "#print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
        "#print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D83lSKHwRWva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}